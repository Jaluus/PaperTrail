{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4acc8ada106b5af",
   "metadata": {},
   "source": [
    "# Training a bipartite GCN\n",
    "\n",
    "Companion to `training_lightgcn.ipynb`, but using the simpler SAGE-based encoder from `modeling/models/simple.py`. This notebook fixes the loss computation used in `training_tests.py` by explicitly separating positive/negative scores before calling `BPR_loss`.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "da4dd2d92e8a7d65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T07:24:55.048414Z",
     "start_time": "2025-12-08T07:24:51.408326Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_scatter import scatter_mean\n",
    "\n",
    "\n",
    "from modeling.losses import BPR_loss\n",
    "from modeling.metrics import calculate_metrics\n",
    "from modeling.sampling import prepare_training_data, sample_minibatch\n",
    "from modeling.layers.bipartite_gcn import BipartiteGCN\n",
    "from modeling.models.TB_simple import TBBaselineModel\n",
    "from modeling.utils import get_coauthor_edges\n",
    "\n",
    "torch.manual_seed(1)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7819d39c6ef0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "4663918ab8183eb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T07:43:22.267789Z",
     "start_time": "2025-12-08T07:43:22.108220Z"
    }
   },
   "source": [
    "# Load data\n",
    "data: HeteroData = torch.load(\"data/hetero_data_no_coauthor.pt\", weights_only=False)\n",
    "\n",
    "paper_ids = data[\"paper\"].node_id\n",
    "paper_embeddings = data[\"paper\"].x\n",
    "author_ids = data[\"author\"].node_id\n",
    "author_embeddings = torch.ones((data[\"author\"].num_nodes, paper_embeddings.shape[1]))\n",
    "\n",
    "edge_index = data[\"author\", \"writes\", \"paper\"].edge_index\n",
    "\n",
    "print(f\"Number of authors: {len(author_ids)}\")\n",
    "print(f\"Number of papers: {len(paper_ids)}\")\n",
    "print(f\"Number of edges: {edge_index.shape[1]}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 90941\n",
      "Number of papers: 63854\n",
      "Number of edges: 320187\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "3eb1c83ab0a123bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T07:43:22.704147Z",
     "start_time": "2025-12-08T07:43:22.666770Z"
    }
   },
   "source": [
    "# Train/val/test split and message-passing vs supervision edges\n",
    "(\n",
    "    message_passing_edge_index,\n",
    "    supervision_edge_index,\n",
    "    val_edge_index_raw,\n",
    "    test_edge_index_raw,\n",
    ") = prepare_training_data(edge_index)\n",
    "\n",
    "# Keep non-offset copies for evaluation (user/item ids remain contiguous)\n",
    "train_edge_index_raw = torch.cat([message_passing_edge_index, supervision_edge_index], dim=1)\n",
    "\n",
    "# Build joint embedding table and offset paper ids so authors/papers share the same adjacency\n",
    "#node_embeddings = torch.cat([author_embeddings, paper_embeddings], dim=0)\n",
    "#edge_index_offset = torch.tensor([0, author_embeddings.shape[0]])\n",
    "message_passing_edge_index = message_passing_edge_index# + edge_index_offset.view(2, 1)\n",
    "supervision_edge_index = supervision_edge_index# +.view(2, 1)\n",
    "val_edge_index = val_edge_index_raw #+ edge_index_offset.view(2, 1)\n",
    "test_edge_index = test_edge_index_raw# + edge_index_offset.view(2, 1)\n",
    "\n",
    "num_authors, num_papers = len(author_ids), len(paper_ids)\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T07:43:39.538815Z",
     "start_time": "2025-12-08T07:43:38.638061Z"
    }
   },
   "cell_type": "code",
   "source": "coauthor_edge_index = get_coauthor_edges(message_passing_edge_index)",
   "id": "76c7c577151639fd",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T08:18:50.946038Z",
     "start_time": "2025-12-08T08:18:50.053703Z"
    }
   },
   "cell_type": "code",
   "source": "lst_coa = coauthor_edge_index.T.tolist()",
   "id": "252405ad2fd9319d",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T08:19:12.662434Z",
     "start_time": "2025-12-08T08:19:12.478800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check for duplicates in lst_coa\n",
    "set_coa = set(tuple(x) for x in lst_coa)\n",
    "len(lst_coa), len(set_coa)"
   ],
   "id": "7d61b14ef9535597",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(543360, 472686)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-08T08:19:34.368557Z",
     "start_time": "2025-12-08T08:19:34.366196Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ff66b054d76fc78d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdeadf5c4513b393",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T02:54:21.164312Z",
     "start_time": "2025-12-06T02:54:21.159907Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90941, 63854)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_authors, num_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e97b1657c34e98b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T02:54:21.218916Z",
     "start_time": "2025-12-06T02:54:21.213930Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "ITERATIONS = 100000\n",
    "BATCH_SIZE = 512\n",
    "LR = 1e-4\n",
    "NEG_SAMPLE_RATIO = 5\n",
    "ITERS_PER_EVAL = 1000\n",
    "K = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4aacd2c2e5908b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T02:54:21.286010Z",
     "start_time": "2025-12-06T02:54:21.270781Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu.\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "model = BipartiteGCN(embedding_dim=paper_embeddings.shape[1], aggr='mean', n_layers=3)\n",
    "#model = TBBaselineModel(hidden_channels=256, data=data)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}.\")\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "author_embeddings = author_embeddings.to(device)\n",
    "paper_embeddings = paper_embeddings.to(device)\n",
    "\n",
    "message_passing_edge_index = message_passing_edge_index.to(device)\n",
    "supervision_edge_index = supervision_edge_index.to(device)\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "test_edge_index = test_edge_index.to(device)\n",
    "train_edge_index_raw = train_edge_index_raw.to(device)\n",
    "val_edge_index_raw = val_edge_index_raw.to(device)\n",
    "test_edge_index_raw = test_edge_index_raw.to(device)\n",
    "coauthor_edge_index = coauthor_edge_index.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a72595e5282900",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T02:54:21.552307Z",
     "start_time": "2025-12-06T02:54:21.330467Z"
    }
   },
   "outputs": [],
   "source": [
    "# Mini-batch sampling (returns positive + negative supervision edges)\n",
    "start_time = time.time()\n",
    "pos_edge_index, neg_edge_index = sample_minibatch(\n",
    "    supervision_edge_index,\n",
    "    BATCH_SIZE,\n",
    "    neg_sample_ratio=NEG_SAMPLE_RATIO,\n",
    ")\n",
    "pos_edge_index = pos_edge_index.to(device)\n",
    "neg_edge_index = neg_edge_index.to(device)\n",
    "batch_edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
    "\n",
    "# Initialize the author embeddings with the averages of their papers according to message_passing_edge_index\n",
    "author_embeddings = scatter_mean(\n",
    "    paper_embeddings[message_passing_edge_index[1]],\n",
    "    message_passing_edge_index[0],\n",
    "    dim=0,\n",
    "    dim_size=author_embeddings.size(0),\n",
    ")\n",
    "\n",
    "# Forward pass\n",
    "start_time = time.time()\n",
    "scores = model(\n",
    "    author_embeddings,\n",
    "    paper_embeddings,\n",
    "    message_passing_edge_index,\n",
    "    coauthor_edge_index,\n",
    "    batch_edge_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8948f318d1f7f41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T02:54:21.560692Z",
     "start_time": "2025-12-06T02:54:21.559168Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba18f6c1509945b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-12-06T02:54:21.607596Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Iter 10/100000] loss: 0.57063, val_recall@20: 0.00082, val_precision@20: 0.00006, train_recall@20: 0.00131, train_precision@20: 0.00012\n",
      "[Iter 20/100000] loss: 0.52034, val_recall@20: 0.00211, val_precision@20: 0.00018, train_recall@20: 0.00214, train_precision@20: 0.00022\n",
      "[Iter 30/100000] loss: 0.50751, val_recall@20: 0.00330, val_precision@20: 0.00024, train_recall@20: 0.00313, train_precision@20: 0.00031\n",
      "[Iter 40/100000] loss: 0.47772, val_recall@20: 0.00519, val_precision@20: 0.00038, train_recall@20: 0.00458, train_precision@20: 0.00046\n",
      "[Iter 50/100000] loss: 0.46787, val_recall@20: 0.00609, val_precision@20: 0.00044, train_recall@20: 0.00495, train_precision@20: 0.00049\n",
      "[Iter 60/100000] loss: 0.42629, val_recall@20: 0.00653, val_precision@20: 0.00046, train_recall@20: 0.00576, train_precision@20: 0.00057\n",
      "[Iter 70/100000] loss: 0.40730, val_recall@20: 0.00873, val_precision@20: 0.00060, train_recall@20: 0.00746, train_precision@20: 0.00074\n",
      "[Iter 80/100000] loss: 0.41625, val_recall@20: 0.00927, val_precision@20: 0.00062, train_recall@20: 0.00911, train_precision@20: 0.00087\n",
      "[Iter 90/100000] loss: 0.40154, val_recall@20: 0.00964, val_precision@20: 0.00066, train_recall@20: 0.00983, train_precision@20: 0.00090\n",
      "[Iter 100/100000] loss: 0.38006, val_recall@20: 0.01006, val_precision@20: 0.00068, train_recall@20: 0.00953, train_precision@20: 0.00089\n",
      "[Iter 110/100000] loss: 0.37092, val_recall@20: 0.00980, val_precision@20: 0.00069, train_recall@20: 0.00957, train_precision@20: 0.00092\n",
      "[Iter 120/100000] loss: 0.41466, val_recall@20: 0.01116, val_precision@20: 0.00077, train_recall@20: 0.01036, train_precision@20: 0.00098\n",
      "[Iter 130/100000] loss: 0.39905, val_recall@20: 0.01114, val_precision@20: 0.00074, train_recall@20: 0.01097, train_precision@20: 0.00103\n",
      "[Iter 140/100000] loss: 0.37366, val_recall@20: 0.01061, val_precision@20: 0.00071, train_recall@20: 0.01075, train_precision@20: 0.00100\n",
      "[Iter 150/100000] loss: 0.42647, val_recall@20: 0.01229, val_precision@20: 0.00084, train_recall@20: 0.01194, train_precision@20: 0.00111\n",
      "[Iter 160/100000] loss: 0.39935, val_recall@20: 0.01290, val_precision@20: 0.00089, train_recall@20: 0.01208, train_precision@20: 0.00114\n",
      "[Iter 170/100000] loss: 0.38641, val_recall@20: 0.01434, val_precision@20: 0.00099, train_recall@20: 0.01292, train_precision@20: 0.00122\n",
      "[Iter 180/100000] loss: 0.40245, val_recall@20: 0.01347, val_precision@20: 0.00092, train_recall@20: 0.01327, train_precision@20: 0.00121\n",
      "[Iter 190/100000] loss: 0.41448, val_recall@20: 0.01402, val_precision@20: 0.00094, train_recall@20: 0.01346, train_precision@20: 0.00123\n",
      "[Iter 200/100000] loss: 0.37240, val_recall@20: 0.01335, val_precision@20: 0.00092, train_recall@20: 0.01323, train_precision@20: 0.00123\n",
      "[Iter 210/100000] loss: 0.40752, val_recall@20: 0.01360, val_precision@20: 0.00093, train_recall@20: 0.01295, train_precision@20: 0.00121\n",
      "[Iter 220/100000] loss: 0.39124, val_recall@20: 0.01379, val_precision@20: 0.00096, train_recall@20: 0.01378, train_precision@20: 0.00128\n",
      "[Iter 230/100000] loss: 0.40654, val_recall@20: 0.01391, val_precision@20: 0.00096, train_recall@20: 0.01413, train_precision@20: 0.00127\n",
      "[Iter 240/100000] loss: 0.35888, val_recall@20: 0.01425, val_precision@20: 0.00102, train_recall@20: 0.01443, train_precision@20: 0.00134\n",
      "[Iter 250/100000] loss: 0.43106, val_recall@20: 0.01465, val_precision@20: 0.00104, train_recall@20: 0.01465, train_precision@20: 0.00138\n",
      "[Iter 260/100000] loss: 0.36571, val_recall@20: 0.01432, val_precision@20: 0.00101, train_recall@20: 0.01467, train_precision@20: 0.00139\n",
      "[Iter 270/100000] loss: 0.40392, val_recall@20: 0.01467, val_precision@20: 0.00104, train_recall@20: 0.01425, train_precision@20: 0.00136\n",
      "[Iter 280/100000] loss: 0.38550, val_recall@20: 0.01401, val_precision@20: 0.00096, train_recall@20: 0.01334, train_precision@20: 0.00127\n",
      "[Iter 290/100000] loss: 0.40270, val_recall@20: 0.01310, val_precision@20: 0.00092, train_recall@20: 0.01319, train_precision@20: 0.00128\n",
      "[Iter 300/100000] loss: 0.39661, val_recall@20: 0.01317, val_precision@20: 0.00091, train_recall@20: 0.01274, train_precision@20: 0.00120\n",
      "[Iter 310/100000] loss: 0.39105, val_recall@20: 0.01466, val_precision@20: 0.00102, train_recall@20: 0.01486, train_precision@20: 0.00134\n",
      "[Iter 320/100000] loss: 0.41745, val_recall@20: 0.01565, val_precision@20: 0.00110, train_recall@20: 0.01622, train_precision@20: 0.00147\n",
      "[Iter 330/100000] loss: 0.39718, val_recall@20: 0.01636, val_precision@20: 0.00114, train_recall@20: 0.01604, train_precision@20: 0.00148\n",
      "[Iter 340/100000] loss: 0.38972, val_recall@20: 0.01729, val_precision@20: 0.00118, train_recall@20: 0.01651, train_precision@20: 0.00156\n",
      "[Iter 350/100000] loss: 0.37546, val_recall@20: 0.01622, val_precision@20: 0.00112, train_recall@20: 0.01699, train_precision@20: 0.00155\n",
      "[Iter 360/100000] loss: 0.41050, val_recall@20: 0.01622, val_precision@20: 0.00114, train_recall@20: 0.01599, train_precision@20: 0.00148\n",
      "[Iter 370/100000] loss: 0.38893, val_recall@20: 0.01550, val_precision@20: 0.00110, train_recall@20: 0.01638, train_precision@20: 0.00149\n",
      "[Iter 380/100000] loss: 0.36221, val_recall@20: 0.01547, val_precision@20: 0.00108, train_recall@20: 0.01582, train_precision@20: 0.00148\n",
      "[Iter 390/100000] loss: 0.39961, val_recall@20: 0.01665, val_precision@20: 0.00115, train_recall@20: 0.01650, train_precision@20: 0.00158\n",
      "[Iter 400/100000] loss: 0.41084, val_recall@20: 0.01553, val_precision@20: 0.00109, train_recall@20: 0.01652, train_precision@20: 0.00154\n",
      "[Iter 410/100000] loss: 0.37851, val_recall@20: 0.01691, val_precision@20: 0.00117, train_recall@20: 0.01649, train_precision@20: 0.00157\n",
      "[Iter 420/100000] loss: 0.38339, val_recall@20: 0.01662, val_precision@20: 0.00113, train_recall@20: 0.01635, train_precision@20: 0.00154\n",
      "[Iter 430/100000] loss: 0.40035, val_recall@20: 0.01721, val_precision@20: 0.00118, train_recall@20: 0.01678, train_precision@20: 0.00156\n",
      "[Iter 440/100000] loss: 0.36850, val_recall@20: 0.01743, val_precision@20: 0.00121, train_recall@20: 0.01736, train_precision@20: 0.00159\n",
      "[Iter 450/100000] loss: 0.39959, val_recall@20: 0.01753, val_precision@20: 0.00120, train_recall@20: 0.01785, train_precision@20: 0.00164\n",
      "[Iter 460/100000] loss: 0.37715, val_recall@20: 0.01776, val_precision@20: 0.00123, train_recall@20: 0.01762, train_precision@20: 0.00163\n",
      "[Iter 470/100000] loss: 0.35780, val_recall@20: 0.01648, val_precision@20: 0.00112, train_recall@20: 0.01712, train_precision@20: 0.00154\n",
      "[Iter 480/100000] loss: 0.38874, val_recall@20: 0.01658, val_precision@20: 0.00115, train_recall@20: 0.01723, train_precision@20: 0.00159\n",
      "[Iter 490/100000] loss: 0.38797, val_recall@20: 0.01733, val_precision@20: 0.00117, train_recall@20: 0.01777, train_precision@20: 0.00165\n",
      "[Iter 500/100000] loss: 0.36960, val_recall@20: 0.01892, val_precision@20: 0.00130, train_recall@20: 0.01785, train_precision@20: 0.00167\n",
      "[Iter 510/100000] loss: 0.38224, val_recall@20: 0.01742, val_precision@20: 0.00116, train_recall@20: 0.01717, train_precision@20: 0.00160\n",
      "[Iter 520/100000] loss: 0.38035, val_recall@20: 0.01929, val_precision@20: 0.00129, train_recall@20: 0.01850, train_precision@20: 0.00168\n",
      "[Iter 530/100000] loss: 0.39164, val_recall@20: 0.01913, val_precision@20: 0.00126, train_recall@20: 0.01812, train_precision@20: 0.00162\n",
      "[Iter 540/100000] loss: 0.36141, val_recall@20: 0.01940, val_precision@20: 0.00130, train_recall@20: 0.01843, train_precision@20: 0.00169\n",
      "[Iter 550/100000] loss: 0.37879, val_recall@20: 0.01914, val_precision@20: 0.00130, train_recall@20: 0.01921, train_precision@20: 0.00172\n",
      "[Iter 560/100000] loss: 0.37679, val_recall@20: 0.01859, val_precision@20: 0.00126, train_recall@20: 0.01884, train_precision@20: 0.00173\n",
      "[Iter 570/100000] loss: 0.35777, val_recall@20: 0.02018, val_precision@20: 0.00138, train_recall@20: 0.02019, train_precision@20: 0.00185\n",
      "[Iter 580/100000] loss: 0.35963, val_recall@20: 0.01862, val_precision@20: 0.00127, train_recall@20: 0.01856, train_precision@20: 0.00167\n",
      "[Iter 590/100000] loss: 0.38252, val_recall@20: 0.01877, val_precision@20: 0.00127, train_recall@20: 0.01805, train_precision@20: 0.00165\n",
      "[Iter 600/100000] loss: 0.40002, val_recall@20: 0.02004, val_precision@20: 0.00136, train_recall@20: 0.01880, train_precision@20: 0.00173\n",
      "[Iter 610/100000] loss: 0.35192, val_recall@20: 0.02180, val_precision@20: 0.00148, train_recall@20: 0.01997, train_precision@20: 0.00182\n",
      "[Iter 620/100000] loss: 0.36848, val_recall@20: 0.02209, val_precision@20: 0.00148, train_recall@20: 0.01992, train_precision@20: 0.00187\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "train_losses = []\n",
    "timings = {\"batching\": [], \"forward\": [], \"loss\": [], \"backward\": []}\n",
    "\n",
    "for iter in range(ITERATIONS):\n",
    "    # Mini-batch sampling (returns positive + negative supervision edges)\n",
    "    start_time = time.time()\n",
    "    pos_edge_index, neg_edge_index = sample_minibatch(\n",
    "        supervision_edge_index,\n",
    "        BATCH_SIZE,\n",
    "        neg_sample_ratio=NEG_SAMPLE_RATIO,\n",
    "    )\n",
    "    pos_edge_index = pos_edge_index.to(device)\n",
    "    neg_edge_index = neg_edge_index.to(device)\n",
    "    batch_edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
    "    timings[\"batching\"].append(time.time() - start_time)\n",
    "\n",
    "    # Forward pass\n",
    "    start_time = time.time()\n",
    "    scores = model(\n",
    "        author_embeddings,\n",
    "        paper_embeddings,\n",
    "        message_passing_edge_index,\n",
    "        coauthor_edge_index,\n",
    "        batch_edge_index,\n",
    "    )\n",
    "    pos_scores = scores[: pos_edge_index.shape[1]]\n",
    "    neg_scores = scores[pos_edge_index.shape[1] :]\n",
    "    timings[\"forward\"].append(time.time() - start_time)\n",
    "\n",
    "    # Correct BPR loss: compare positive vs negative scores\n",
    "    start_time = time.time()\n",
    "    train_loss = BPR_loss(pos_scores, neg_scores)\n",
    "    timings[\"loss\"].append(time.time() - start_time)\n",
    "\n",
    "    # Backward\n",
    "    start_time = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
    "    grad_norm_value = float(grad_norm)\n",
    "    optimizer.step()\n",
    "    timings[\"backward\"].append(time.time() - start_time)\n",
    "\n",
    "    if (iter + 1) % ITERS_PER_EVAL == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            user_embedding, item_embedding = model.get_embeddings(author_embeddings, paper_embeddings, message_passing_edge_index, coauthor_edge_index)\n",
    "\n",
    "        val_recall, val_precision = calculate_metrics(\n",
    "            user_embedding,\n",
    "            item_embedding,\n",
    "            val_edge_index_raw,\n",
    "            [train_edge_index_raw],\n",
    "            K,\n",
    "            batch_size=512,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        train_recall, train_precision = calculate_metrics(\n",
    "            user_embedding,\n",
    "            item_embedding,\n",
    "            supervision_edge_index,\n",
    "            [message_passing_edge_index],\n",
    "            K,\n",
    "            batch_size=1024,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"[Iter {iter + 1}/{ITERATIONS}] loss: {train_loss.item():.5f}, grad_norm: {grad_norm_value:.5f}, val_recall@{K}: {val_recall:.5f}, val_precision@{K}: {val_precision:.5f}, train_recall@{K}: {train_recall:.5f}, train_precision@{K}: {train_precision:.5f}\"\n",
    "        )\n",
    "        train_losses.append(train_loss.item())\n",
    "        model.train()\n",
    "\n",
    "print(\"Training done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67c52ccebae74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and timing curves\n",
    "iters = [i * ITERS_PER_EVAL for i in range(len(train_losses))]\n",
    "plt.plot(iters, train_losses, label=\"train\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"training loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(\"training_bGCN_loss.png\")\n",
    "\n",
    "plt.plot(timings[\"batching\"][5:], label=\"batching\")\n",
    "plt.plot(timings[\"forward\"][5:], label=\"forwarding\")\n",
    "plt.plot(timings[\"loss\"][5:], label=\"loss computation\")\n",
    "plt.plot(timings[\"backward\"][5:], label=\"backwarding\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"time (s)\")\n",
    "plt.title(\"time per operation\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(\"training_bGCN_timing.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6ae321700980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final test evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    user_embedding, item_embedding = model.get_embeddings(author_embeddings, paper_embeddings, message_passing_edge_index, coauthor_edge_index)\n",
    "\n",
    "test_recall, test_precision = calculate_metrics(\n",
    "    user_embedding,\n",
    "    item_embedding,\n",
    "    test_edge_index_raw,\n",
    "    [train_edge_index_raw, val_edge_index_raw],\n",
    "    K,\n",
    "    batch_size=512,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(f\"[test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaperTrailCPU",
   "language": "python",
   "name": "papertrailcpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
