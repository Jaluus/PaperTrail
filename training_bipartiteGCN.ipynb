{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the simple GNN recommender\n",
    "\n",
    "Companion to `training_lightgcn.ipynb`, but using the simpler SAGE-based encoder from `modeling/models/simple.py`. This notebook fixes the loss computation used in `training_tests.py` by explicitly separating positive/negative scores before calling `BPR_loss`.\n"
   ],
   "id": "e4acc8ada106b5af"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T01:28:39.922377Z",
     "start_time": "2025-12-06T01:28:39.909609Z"
    }
   },
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch_geometric.data import HeteroData\n",
    "\n",
    "from modeling.losses import BPR_loss\n",
    "from modeling.metrics import calculate_metrics\n",
    "from modeling.models.simple import Model\n",
    "from modeling.sampling import prepare_training_data, sample_minibatch\n",
    "\n",
    "torch.manual_seed(1)\n"
   ],
   "id": "da4dd2d92e8a7d65",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x76dc2b2b3eb0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T01:28:41.373089Z",
     "start_time": "2025-12-06T01:28:41.211432Z"
    }
   },
   "source": [
    "# Load data\n",
    "data: HeteroData = torch.load(\"data/hetero_data_no_coauthor.pt\", weights_only=False)\n",
    "\n",
    "paper_ids = data[\"paper\"].node_id\n",
    "paper_embeddings = data[\"paper\"].x\n",
    "author_ids = data[\"author\"].node_id\n",
    "author_embeddings = torch.ones((data[\"author\"].num_nodes, paper_embeddings.shape[1]))\n",
    "edge_index = data[\"author\", \"writes\", \"paper\"].edge_index\n",
    "\n",
    "print(f\"Number of authors: {len(author_ids)}\")\n",
    "print(f\"Number of papers: {len(paper_ids)}\")\n",
    "print(f\"Number of edges: {edge_index.shape[1]}\")\n"
   ],
   "id": "4663918ab8183eb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of authors: 90941\n",
      "Number of papers: 63854\n",
      "Number of edges: 320187\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T01:06:10.513564Z",
     "start_time": "2025-12-06T01:06:10.410474Z"
    }
   },
   "source": [
    "# Train/val/test split and message-passing vs supervision edges\n",
    "(\n",
    "    message_passing_edge_index,\n",
    "    supervision_edge_index,\n",
    "    val_edge_index_raw,\n",
    "    test_edge_index_raw,\n",
    ") = prepare_training_data(edge_index)\n",
    "\n",
    "# Keep non-offset copies for evaluation (user/item ids remain contiguous)\n",
    "train_edge_index_raw = torch.cat([message_passing_edge_index, supervision_edge_index], dim=1)\n",
    "\n",
    "# Build joint embedding table and offset paper ids so authors/papers share the same adjacency\n",
    "node_embeddings = torch.cat([author_embeddings, paper_embeddings], dim=0)\n",
    "edge_index_offset = torch.tensor([0, author_embeddings.shape[0]])\n",
    "message_passing_edge_index = message_passing_edge_index + edge_index_offset.view(2, 1)\n",
    "supervision_edge_index = supervision_edge_index + edge_index_offset.view(2, 1)\n",
    "val_edge_index = val_edge_index_raw + edge_index_offset.view(2, 1)\n",
    "test_edge_index = test_edge_index_raw + edge_index_offset.view(2, 1)\n",
    "\n",
    "num_authors, num_papers = len(author_ids), len(paper_ids)\n"
   ],
   "id": "3eb1c83ab0a123bf",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-06T01:08:41.078703Z",
     "start_time": "2025-12-06T01:08:41.071973Z"
    }
   },
   "cell_type": "code",
   "source": "num_authors, num_papers",
   "id": "bdeadf5c4513b393",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90941, 63854)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "ITERATIONS = 10000\n",
    "BATCH_SIZE = 512\n",
    "LR = 5e-3\n",
    "NEG_SAMPLE_RATIO = 5\n",
    "ITERS_PER_EVAL = 1000\n",
    "K = 20\n"
   ],
   "id": "e97b1657c34e98b4"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setup\n",
    "model = Model(embedding_dim=paper_embeddings.shape[1])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device {device}.\")\n",
    "\n",
    "model = model.to(device)\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "node_embeddings = node_embeddings.to(device)\n",
    "message_passing_edge_index = message_passing_edge_index.to(device)\n",
    "supervision_edge_index = supervision_edge_index.to(device)\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "test_edge_index = test_edge_index.to(device)\n",
    "train_edge_index_raw = train_edge_index_raw.to(device)\n",
    "val_edge_index_raw = val_edge_index_raw.to(device)\n",
    "test_edge_index_raw = test_edge_index_raw.to(device)\n"
   ],
   "id": "e4aacd2c2e5908b4"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Training loop\n",
    "train_losses = []\n",
    "timings = {\"batching\": [], \"forward\": [], \"loss\": [], \"backward\": []}\n",
    "\n",
    "for iter in range(ITERATIONS):\n",
    "    # Mini-batch sampling (returns positive + negative supervision edges)\n",
    "    start_time = time.time()\n",
    "    pos_edge_index, neg_edge_index = sample_minibatch(\n",
    "        supervision_edge_index,\n",
    "        BATCH_SIZE,\n",
    "        neg_sample_ratio=NEG_SAMPLE_RATIO,\n",
    "    )\n",
    "    pos_edge_index = pos_edge_index.to(device)\n",
    "    neg_edge_index = neg_edge_index.to(device)\n",
    "    batch_edge_index = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n",
    "    timings[\"batching\"].append(time.time() - start_time)\n",
    "\n",
    "    # Forward pass\n",
    "    start_time = time.time()\n",
    "    scores = model(\n",
    "        node_embeddings,\n",
    "        message_passing_edge_index,\n",
    "        batch_edge_index,\n",
    "    )\n",
    "    pos_scores = scores[: pos_edge_index.shape[1]]\n",
    "    neg_scores = scores[pos_edge_index.shape[1] :]\n",
    "    timings[\"forward\"].append(time.time() - start_time)\n",
    "\n",
    "    # Correct BPR loss: compare positive vs negative scores\n",
    "    start_time = time.time()\n",
    "    train_loss = BPR_loss(pos_scores, neg_scores)\n",
    "    timings[\"loss\"].append(time.time() - start_time)\n",
    "\n",
    "    # Backward\n",
    "    start_time = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    train_loss.backward()\n",
    "    optimizer.step()\n",
    "    timings[\"backward\"].append(time.time() - start_time)\n",
    "\n",
    "    if (iter + 1) % ITERS_PER_EVAL == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            node_emb = model.get_node_embeddings(node_embeddings, message_passing_edge_index)\n",
    "            user_embedding = node_emb[:num_authors]\n",
    "            item_embedding = node_emb[num_authors:]\n",
    "\n",
    "        val_recall, val_precision = calculate_metrics(\n",
    "            user_embedding,\n",
    "            item_embedding,\n",
    "            val_edge_index_raw,\n",
    "            [train_edge_index_raw],\n",
    "            K,\n",
    "            batch_size=512,\n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        train_recall, train_precision = calculate_metrics(\n",
    "            user_embedding,\n",
    "            item_embedding,\n",
    "            supervision_edge_index,\n",
    "            [message_passing_edge_index],\n",
    "            K,\n",
    "            batch_size=1024,\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"[Iter {iter + 1}/{ITERATIONS}] loss: {train_loss.item():.5f}, val_recall@{K}: {val_recall:.5f}, val_precision@{K}: {val_precision:.5f}\"\n",
    "        )\n",
    "        train_losses.append(train_loss.item())\n",
    "        model.train()\n",
    "\n",
    "print(\"Training done.\")\n"
   ],
   "id": "dba18f6c1509945b"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Loss and timing curves\n",
    "iters = [i * ITERS_PER_EVAL for i in range(len(train_losses))]\n",
    "plt.plot(iters, train_losses, label=\"train\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.title(\"training loss\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(\"training_simple_loss.png\")\n",
    "\n",
    "plt.plot(timings[\"batching\"][5:], label=\"batching\")\n",
    "plt.plot(timings[\"forward\"][5:], label=\"forwarding\")\n",
    "plt.plot(timings[\"loss\"][5:], label=\"loss computation\")\n",
    "plt.plot(timings[\"backward\"][5:], label=\"backwarding\")\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"time (s)\")\n",
    "plt.title(\"time per operation\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(\"training_simple_timing.png\")\n"
   ],
   "id": "c67c52ccebae74b"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Final test evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    node_emb = model.get_node_embeddings(node_embeddings, message_passing_edge_index)\n",
    "    user_embedding = node_emb[:num_authors]\n",
    "    item_embedding = node_emb[num_authors:]\n",
    "\n",
    "test_recall, test_precision = calculate_metrics(\n",
    "    user_embedding,\n",
    "    item_embedding,\n",
    "    test_edge_index_raw,\n",
    "    [train_edge_index_raw, val_edge_index_raw],\n",
    "    K,\n",
    "    batch_size=512,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "print(f\"[test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}\")\n"
   ],
   "id": "eff6ae321700980e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaperTrailCPU",
   "language": "python",
   "name": "papertrailcpu"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "mimetype": "text/x-python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
