{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWkNAZvtNQ6R"
      },
      "source": [
        "# Implementing a Recommender System using LightGCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OBSacx6Q03m"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from modeling.sampling import sample_mini_batch\n",
        "from modeling.models.lightGCN import LightGCN\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "\n",
        "from torch_sparse import SparseTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o2P3zYR8Q8EX"
      },
      "outputs": [],
      "source": [
        "# Lets start by loading the data\n",
        "data = torch.load(\"data/hetero_data_no_coauthor.pt\", weights_only=False)\n",
        "\n",
        "# We only need the edges for light GCN\n",
        "edge_index = data[\"author\", \"writes\", \"paper\"].edge_index\n",
        "author_ids = data[\"author\"].node_id\n",
        "paper_ids = data[\"paper\"].node_id\n",
        "\n",
        "print(f\"Number of authors: {len(author_ids)}\")\n",
        "print(f\"Number of papers: {len(paper_ids)}\")\n",
        "print(f\"Number of edges: {edge_index.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wIueYZfaT6_H"
      },
      "outputs": [],
      "source": [
        "# split the edges of the graph using a 80/10/10 train/validation/test split\n",
        "num_authors, num_papers = len(author_ids), len(paper_ids)\n",
        "num_interactions = edge_index.shape[1]\n",
        "all_indices = [i for i in range(num_interactions)]\n",
        "\n",
        "# Here we enumearte the edges\n",
        "# Then we split them into train, val, test sets\n",
        "train_indices, test_indices = train_test_split(\n",
        "    all_indices,\n",
        "    test_size=0.2,\n",
        "    random_state=1,\n",
        ")\n",
        "val_indices, test_indices = train_test_split(\n",
        "    test_indices,\n",
        "    test_size=0.5,\n",
        "    random_state=1,\n",
        ")\n",
        "\n",
        "train_edge_index = edge_index[:, train_indices]\n",
        "val_edge_index = edge_index[:, val_indices]\n",
        "test_edge_index = edge_index[:, test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U5yKILBJUAN6"
      },
      "outputs": [],
      "source": [
        "# # convert edge indices into Sparse Tensors: https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html\n",
        "# # We dont need to do this, but it is more efficient for large graphs\n",
        "\n",
        "train_sparse_edge_index = SparseTensor(\n",
        "    row=train_edge_index[0],\n",
        "    col=train_edge_index[1],\n",
        "    sparse_sizes=(num_authors + num_papers, num_authors + num_papers),\n",
        ")\n",
        "val_sparse_edge_index = SparseTensor(\n",
        "    row=val_edge_index[0],\n",
        "    col=val_edge_index[1],\n",
        "    sparse_sizes=(num_authors + num_papers, num_authors + num_papers),\n",
        ")\n",
        "test_sparse_edge_index = SparseTensor(\n",
        "    row=test_edge_index[0],\n",
        "    col=test_edge_index[1],\n",
        "    sparse_sizes=(num_authors + num_papers, num_authors + num_papers),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmPs1xS-BYfe"
      },
      "outputs": [],
      "source": [
        "def bpr_loss(\n",
        "    author_emb_final,\n",
        "    pos_paper_emb_final,\n",
        "    neg_paper_emb_final,\n",
        "):\n",
        "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
        "\n",
        "\n",
        "    Args:\n",
        "        users_emb_final (torch.Tensor): e_u_k\n",
        "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
        "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: scalar bpr loss value\n",
        "    \"\"\"\n",
        "    # L_{BPR} = - \\frac{1}{|E_{pos}(u^*)|\\cdot|E_{neg}(u^*)|} \\sum_{(u^*,v_{pos}) \\in E_{pos}(u^*)} \\sum_{(u^*,v_{neg}) \\in E_{neg}(u^*)} -log(f_\\theta(u^*, v_{pos}) - f_\\theta(u^*, v_{neg}))\n",
        "    \n",
        "    # We first get the positive and negative scores\n",
        "    pos_scores = torch.sum(author_emb_final * pos_paper_emb_final, dim=-1)\n",
        "    neg_scores = torch.sum(author_emb_final * neg_paper_emb_final, dim=-1)\n",
        "\n",
        "    # Now we compute the loss, currently its assuming each node only has one positive and one negative sample\n",
        "    loss = -torch.mean(torch.log(torch.sigmoid(pos_scores - neg_scores)))\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nHO2gdhRSwzJ"
      },
      "outputs": [],
      "source": [
        "# helper function to get N_u\n",
        "def get_author_positive_papers(edge_index):\n",
        "    \"\"\"Generates dictionary of positive items for each user\n",
        "\n",
        "    Args:\n",
        "        edge_index (torch.Tensor): 2 by N list of edges\n",
        "\n",
        "    Returns:\n",
        "        dict: dictionary of positive items for each user\n",
        "    \"\"\"\n",
        "    author_pos_papers = {}\n",
        "    for i in range(edge_index.shape[1]):\n",
        "        author = edge_index[0][i].item()\n",
        "        paper = edge_index[1][i].item()\n",
        "        if author not in author_pos_papers:\n",
        "            author_pos_papers[author] = []\n",
        "        author_pos_papers[author].append(paper)\n",
        "    return author_pos_papers\n",
        "\n",
        "\n",
        "# computes recall@K and precision@K\n",
        "def RecallPrecision_ATk(groundTruth, r, k):\n",
        "    \"\"\"Computers recall @ k and precision @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (intg): determines the top k items to compute precision and recall on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k\n",
        "    \"\"\"\n",
        "    num_correct_pred = torch.sum(\n",
        "        r, dim=-1\n",
        "    )  # number of correctly predicted items per user\n",
        "    # number of items liked by each user in the test set\n",
        "    user_num_liked = torch.Tensor(\n",
        "        [len(groundTruth[i]) for i in range(len(groundTruth))]\n",
        "    )\n",
        "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
        "    precision = torch.mean(num_correct_pred) / k\n",
        "    return recall.item(), precision.item()\n",
        "\n",
        "\n",
        "# computes NDCG@K\n",
        "def NDCGatK_r(groundTruth, r, k):\n",
        "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (int): determines the top k items to compute ndcg on\n",
        "\n",
        "    Returns:\n",
        "        float: ndcg @ k\n",
        "    \"\"\"\n",
        "    assert len(r) == len(groundTruth)\n",
        "\n",
        "    test_matrix = torch.zeros((len(r), k))\n",
        "\n",
        "    for i, items in enumerate(groundTruth):\n",
        "        length = min(len(items), k)\n",
        "        test_matrix[i, :length] = 1\n",
        "    max_r = test_matrix\n",
        "    idcg = torch.sum(max_r * 1.0 / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
        "    dcg = r * (1.0 / torch.log2(torch.arange(2, k + 2)))\n",
        "    dcg = torch.sum(dcg, axis=1)\n",
        "    idcg[idcg == 0.0] = 1.0\n",
        "    ndcg = dcg / idcg\n",
        "    ndcg[torch.isnan(ndcg)] = 0.0\n",
        "    return torch.mean(ndcg).item()\n",
        "\n",
        "\n",
        "def get_metrics(\n",
        "    model,\n",
        "    edge_index,\n",
        "    exclude_edge_indices,\n",
        "    k,\n",
        "    batch_size=1024,\n",
        "    device=None,\n",
        "):\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "\n",
        "    user_embedding = model.authors_emb.weight.to(device)\n",
        "    item_embedding = model.papers_emb.weight.to(device)\n",
        "\n",
        "    users = edge_index[0].unique()\n",
        "    test_user_pos_items = get_author_positive_papers(edge_index)\n",
        "\n",
        "    # Precompute “seen” items (train/val/test) per user to mask\n",
        "    exclude_dicts = [get_author_positive_papers(ei) for ei in exclude_edge_indices]\n",
        "\n",
        "    r_all = []\n",
        "    for start in range(0, users.numel(), batch_size):\n",
        "        batch_users = users[start : start + batch_size]\n",
        "        u_ids = batch_users.tolist()\n",
        "        u_emb = user_embedding[batch_users].to(device)  # [B, d]\n",
        "\n",
        "        rating = torch.matmul(u_emb, item_embedding.T)  # [B, num_items]\n",
        "\n",
        "        # mask excluded items for each user in this batch\n",
        "        for row, u in enumerate(u_ids):\n",
        "            seen_items = set()\n",
        "            for d in exclude_dicts:\n",
        "                seen_items.update(d.get(u, []))\n",
        "            if seen_items:\n",
        "                rating[row, list(seen_items)] = -(1 << 10)\n",
        "\n",
        "        _, top_K_items = torch.topk(rating, k=k, dim=1)  # [B, k]\n",
        "\n",
        "        # build r for this batch\n",
        "        for row, u in enumerate(u_ids):\n",
        "            ground_truth_items = test_user_pos_items[u]\n",
        "            label = [int(i in ground_truth_items) for i in top_K_items[row].tolist()]\n",
        "            r_all.append(label)\n",
        "\n",
        "    r = torch.tensor(r_all, dtype=torch.float32)\n",
        "    test_user_pos_items_list = [test_user_pos_items[u.item()] for u in users]\n",
        "\n",
        "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
        "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
        "    return recall, precision, ndcg\n",
        "\n",
        "\n",
        "# wrapper function to evaluate model\n",
        "def evaluation(\n",
        "    model,\n",
        "    edge_index,\n",
        "    sparse_edge_index,\n",
        "    exclude_edge_indices,\n",
        "    k,\n",
        "):\n",
        "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        k (int): determines the top k items to compute metrics on\n",
        "\n",
        "    Returns:\n",
        "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    # get embeddings\n",
        "    (\n",
        "        users_emb_final,\n",
        "        items_emb_final,\n",
        "    ) = model.forward(sparse_edge_index)\n",
        "\n",
        "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n",
        "        edge_index,\n",
        "        batch_size=128,\n",
        "    )\n",
        "    users_emb_final = users_emb_final[user_indices]\n",
        "    pos_items_emb_final = items_emb_final[pos_item_indices]\n",
        "    neg_items_emb_final = items_emb_final[neg_item_indices]\n",
        "\n",
        "    loss = bpr_loss(\n",
        "        users_emb_final,\n",
        "        pos_items_emb_final,\n",
        "        neg_items_emb_final,\n",
        "    ).item()\n",
        "\n",
        "    recall, precision, ndcg = get_metrics(model, edge_index, exclude_edge_indices, k)\n",
        "\n",
        "    return loss, recall, precision, ndcg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYw1cUgPTjws"
      },
      "source": [
        "# Training\n",
        "\n",
        "Your test set performance should be in line with the following (*K=20*):\n",
        "\n",
        "*Recall@K: 0.13, Precision@K: 0.045, NDCG@K: 0.10*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQL2W-NQTeFd"
      },
      "outputs": [],
      "source": [
        "# define contants\n",
        "ITERATIONS = 10000\n",
        "BATCH_SIZE = 1024\n",
        "LR = 1e-3\n",
        "ITERS_PER_EVAL = 200\n",
        "ITERS_PER_LR_DECAY = 200\n",
        "K = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49JDkBtKTfE-",
        "outputId": "0a62891e-4a65-4b8c-c5d1-1316281b50c9"
      },
      "outputs": [],
      "source": [
        "# setup\n",
        "model = LightGCN(\n",
        "    num_authors=num_authors,\n",
        "    num_papers=num_papers,\n",
        "    embedding_dim=64,\n",
        "    K=6,\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device {device}.\")\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "edge_index = edge_index.to(device)\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
        "\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "val_sparse_edge_index = val_sparse_edge_index.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYjrDp1w-hiP",
        "outputId": "ce7f5102-2090-44a0-8245-42fa30853679"
      },
      "outputs": [],
      "source": [
        "\n",
        "# training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for iter in range(ITERATIONS):\n",
        "    # forward propagation\n",
        "    authors_emb_final, papers_emb_final = model.forward(train_sparse_edge_index)\n",
        "\n",
        "    # mini batching\n",
        "    (\n",
        "        batched_author_indices,\n",
        "        batched_pos_paper_indices,\n",
        "        batched_neg_paper_indices,\n",
        "    ) = sample_mini_batch(\n",
        "        train_edge_index,\n",
        "        BATCH_SIZE,\n",
        "    )\n",
        "\n",
        "    batched_author_indices = batched_author_indices.to(device)\n",
        "    batched_pos_paper_indices = batched_pos_paper_indices.to(device)\n",
        "    batched_neg_paper_indices = batched_neg_paper_indices.to(device)\n",
        "\n",
        "    authors_emb_final = authors_emb_final[batched_author_indices]\n",
        "    pos_paper_emb_final = papers_emb_final[batched_pos_paper_indices]\n",
        "    neg_paper_emb_final = papers_emb_final[batched_neg_paper_indices]\n",
        "\n",
        "    # loss computation\n",
        "    train_loss = bpr_loss(\n",
        "        authors_emb_final,\n",
        "        pos_paper_emb_final,\n",
        "        neg_paper_emb_final,\n",
        "    )\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if iter % ITERS_PER_EVAL == 0:\n",
        "        model.eval()\n",
        "        val_loss, recall, precision, ndcg = evaluation(\n",
        "            model,\n",
        "            val_edge_index,\n",
        "            val_sparse_edge_index,\n",
        "            [train_edge_index],\n",
        "            K,\n",
        "        )\n",
        "        print(\n",
        "            f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\"\n",
        "        )\n",
        "        train_losses.append(train_loss.item())\n",
        "        val_losses.append(val_loss)\n",
        "        model.train()\n",
        "\n",
        "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
        "        scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "nLcdvV5iXBSv",
        "outputId": "b4059176-24b0-46b5-ea65-68c2f9afd6d2"
      },
      "outputs": [],
      "source": [
        "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
        "plt.plot(iters, train_losses, label=\"train\")\n",
        "plt.plot(iters, val_losses, label=\"validation\")\n",
        "plt.xlabel(\"iteration\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.title(\"training and validation loss curves\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6UjCTMQ_N5e",
        "outputId": "56d092d1-df05-4e7d-f2d9-5deead054d7c"
      },
      "outputs": [],
      "source": [
        "# Old Loss:     [test_loss:-0.74255, test_recall@20: 0.00677, test_precision@20: 0.00047, test_ndcg@20: 0.00317\n",
        "# New loss:     [test_loss: 0.67538, test_recall@20: 0.04614, test_precision@20: 0.00417, test_ndcg@20: 0.02455\n",
        "\n",
        "# evaluate on test set\n",
        "model.eval()\n",
        "test_edge_index = test_edge_index.to(device)\n",
        "test_sparse_edge_index = test_sparse_edge_index.to(device)\n",
        "\n",
        "test_loss, test_recall, test_precision, test_ndcg = evaluation(\n",
        "    model,\n",
        "    test_edge_index,\n",
        "    test_sparse_edge_index,\n",
        "    [train_edge_index, val_edge_index],\n",
        "    K,\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gnn",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
