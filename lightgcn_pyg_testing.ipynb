{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWkNAZvtNQ6R"
      },
      "source": [
        "# Implementing a Recommender System using LightGCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5OBSacx6Q03m"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from utils import sample_mini_batch\n",
        "from lightGCN import LightGCN\n",
        "\n",
        "import torch\n",
        "from torch import optim\n",
        "\n",
        "from torch_sparse import SparseTensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "o2P3zYR8Q8EX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of authors: 90941\n",
            "Number of papers: 63854\n",
            "Number of edges: 320187\n"
          ]
        }
      ],
      "source": [
        "# Lets start by loading the data\n",
        "data = torch.load(\"data/hetero_data_no_coauthor.pt\", weights_only=False)\n",
        "\n",
        "# We only need the edges for light GCN\n",
        "edge_index = data[\"author\", \"writes\", \"paper\"].edge_index\n",
        "author_ids = data[\"author\"].node_id\n",
        "paper_ids = data[\"paper\"].node_id\n",
        "\n",
        "print(f\"Number of authors: {len(author_ids)}\")\n",
        "print(f\"Number of papers: {len(paper_ids)}\")\n",
        "print(f\"Number of edges: {edge_index.shape[1]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wIueYZfaT6_H"
      },
      "outputs": [],
      "source": [
        "# split the edges of the graph using a 80/10/10 train/validation/test split\n",
        "num_authors, num_papers = len(author_ids), len(paper_ids)\n",
        "num_interactions = edge_index.shape[1]\n",
        "all_indices = [i for i in range(num_interactions)]\n",
        "\n",
        "# Here we enumearte the edges\n",
        "# Then we split them into train, val, test sets\n",
        "train_indices, test_indices = train_test_split(\n",
        "    all_indices,\n",
        "    test_size=0.2,\n",
        "    random_state=1,\n",
        ")\n",
        "val_indices, test_indices = train_test_split(\n",
        "    test_indices,\n",
        "    test_size=0.5,\n",
        "    random_state=1,\n",
        ")\n",
        "\n",
        "train_edge_index = edge_index[:, train_indices]\n",
        "val_edge_index = edge_index[:, val_indices]\n",
        "test_edge_index = edge_index[:, test_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "U5yKILBJUAN6"
      },
      "outputs": [],
      "source": [
        "# convert edge indices into Sparse Tensors: https://pytorch-geometric.readthedocs.io/en/latest/notes/sparse_tensor.html\n",
        "# We dont need to do this, but it is more efficient for large graphs\n",
        "\n",
        "train_sparse_edge_index = SparseTensor(\n",
        "    row=train_edge_index[0],\n",
        "    col=train_edge_index[1],\n",
        "    sparse_sizes=(num_authors + num_papers, num_authors + num_papers),\n",
        ")\n",
        "val_sparse_edge_index = SparseTensor(\n",
        "    row=val_edge_index[0],\n",
        "    col=val_edge_index[1],\n",
        "    sparse_sizes=(num_authors + num_papers, num_authors + num_papers),\n",
        ")\n",
        "test_sparse_edge_index = SparseTensor(\n",
        "    row=test_edge_index[0],\n",
        "    col=test_edge_index[1],\n",
        "    sparse_sizes=(num_authors + num_papers, num_authors + num_papers),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My8eqloiBccE"
      },
      "source": [
        "# Loss Function\n",
        "\n",
        "\n",
        "\n",
        "We utilize a Bayesian Personalized Ranking (BPR) loss, a pairwise objective which encourages the predictions of positive samples to be higher than negative samples for each user.\n",
        "\n",
        "\\begin{equation}\n",
        "L_{BPR} = -\\sum_{u = 1}^M \\sum_{i \\in N_u} \\sum_{j \\notin N_u} \\ln{\\sigma(\\hat{y}_{ui} - \\hat{y}_{uj})} \n",
        "\\end{equation}\n",
        "\n",
        "$\\hat{y}_{u}$: predicted score of a positive sample\n",
        "\n",
        "$\\hat{y}_{uj}$: predicted score of a negative sample\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QmPs1xS-BYfe"
      },
      "outputs": [],
      "source": [
        "def bpr_loss(\n",
        "    users_emb_final,\n",
        "    pos_items_emb_final,\n",
        "    neg_items_emb_final,\n",
        "):\n",
        "    \"\"\"Bayesian Personalized Ranking Loss as described in https://arxiv.org/abs/1205.2618\n",
        "\n",
        "    Args:\n",
        "        users_emb_final (torch.Tensor): e_u_k\n",
        "        pos_items_emb_final (torch.Tensor): positive e_i_k\n",
        "        neg_items_emb_final (torch.Tensor): negative e_i_k\n",
        "        lambda_val (float): lambda value for regularization loss term\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: scalar bpr loss value\n",
        "    \"\"\"\n",
        "\n",
        "    pos_scores = torch.mul(users_emb_final, pos_items_emb_final)\n",
        "    pos_scores = torch.sum(pos_scores, dim=-1)  # predicted scores of positive samples\n",
        "    neg_scores = torch.mul(users_emb_final, neg_items_emb_final)\n",
        "    neg_scores = torch.sum(neg_scores, dim=-1)  # predicted scores of negative samples\n",
        "\n",
        "    loss = -torch.mean(torch.nn.functional.softplus(pos_scores - neg_scores))\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS7HVr3qLQGx"
      },
      "source": [
        "# Evaluation Metrics\n",
        "\n",
        "We evalaluate our model using the following metrics\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Recall} = \\frac{TP}{TP + FP}\n",
        "\\end{equation}\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{Precision} = \\frac{TP}{TP + FN}\n",
        "\\end{equation}\n",
        "\n",
        "**Dicounted Cumulative Gain (DCG)** at rank position p is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{DCG}_\\text{p} = \\sum_{i = 1}^p \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
        "\\end{equation}\n",
        "\n",
        "p: a particular rank position\n",
        "\n",
        "$rel_i \\in \\{0, 1\\}$ : graded relevance of the result at position $i$\n",
        "\n",
        "**Idealised Dicounted Cumulative Gain (IDCG)**, namely the maximum possible DCG, at rank position $p$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{IDCG}_\\text{p} = \\sum_{i = 1}^{|REL_p|} \\frac{2^{rel_i} - 1}{\\log_2{(i + 1)}}\n",
        "\\end{equation}\n",
        "\n",
        "$|REL_p|$ : list of items ordered by their relevance up to position p\n",
        "\n",
        "**Normalized Dicounted Cumulative Gain (NDCG)** at rank position $p$ is defined as:\n",
        "\n",
        "\\begin{equation}\n",
        "\\text{nDCG}_\\text{p} = \\frac{\\text{DCG}_p}{\\text{nDCG}_p}\n",
        "\\end{equation}\n",
        "\n",
        "Specifically, we use the metrics recall@K, precision@K, and NDCG@K. @K indicates that these metrics are computed on the top K recommendations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nHO2gdhRSwzJ"
      },
      "outputs": [],
      "source": [
        "# helper function to get N_u\n",
        "def get_author_positive_papers(edge_index):\n",
        "    \"\"\"Generates dictionary of positive items for each user\n",
        "\n",
        "    Args:\n",
        "        edge_index (torch.Tensor): 2 by N list of edges\n",
        "\n",
        "    Returns:\n",
        "        dict: dictionary of positive items for each user\n",
        "    \"\"\"\n",
        "    author_pos_papers = {}\n",
        "    for i in range(edge_index.shape[1]):\n",
        "        author = edge_index[0][i].item()\n",
        "        paper = edge_index[1][i].item()\n",
        "        if author not in author_pos_papers:\n",
        "            author_pos_papers[author] = []\n",
        "        author_pos_papers[author].append(paper)\n",
        "    return author_pos_papers\n",
        "\n",
        "\n",
        "# computes recall@K and precision@K\n",
        "def RecallPrecision_ATk(groundTruth, r, k):\n",
        "    \"\"\"Computers recall @ k and precision @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (intg): determines the top k items to compute precision and recall on\n",
        "\n",
        "    Returns:\n",
        "        tuple: recall @ k, precision @ k\n",
        "    \"\"\"\n",
        "    num_correct_pred = torch.sum(\n",
        "        r, dim=-1\n",
        "    )  # number of correctly predicted items per user\n",
        "    # number of items liked by each user in the test set\n",
        "    user_num_liked = torch.Tensor(\n",
        "        [len(groundTruth[i]) for i in range(len(groundTruth))]\n",
        "    )\n",
        "    recall = torch.mean(num_correct_pred / user_num_liked)\n",
        "    precision = torch.mean(num_correct_pred) / k\n",
        "    return recall.item(), precision.item()\n",
        "\n",
        "\n",
        "# computes NDCG@K\n",
        "def NDCGatK_r(groundTruth, r, k):\n",
        "    \"\"\"Computes Normalized Discounted Cumulative Gain (NDCG) @ k\n",
        "\n",
        "    Args:\n",
        "        groundTruth (list): list of lists containing highly rated items of each user\n",
        "        r (list): list of lists indicating whether each top k item recommended to each user\n",
        "            is a top k ground truth item or not\n",
        "        k (int): determines the top k items to compute ndcg on\n",
        "\n",
        "    Returns:\n",
        "        float: ndcg @ k\n",
        "    \"\"\"\n",
        "    assert len(r) == len(groundTruth)\n",
        "\n",
        "    test_matrix = torch.zeros((len(r), k))\n",
        "\n",
        "    for i, items in enumerate(groundTruth):\n",
        "        length = min(len(items), k)\n",
        "        test_matrix[i, :length] = 1\n",
        "    max_r = test_matrix\n",
        "    idcg = torch.sum(max_r * 1.0 / torch.log2(torch.arange(2, k + 2)), axis=1)\n",
        "    dcg = r * (1.0 / torch.log2(torch.arange(2, k + 2)))\n",
        "    dcg = torch.sum(dcg, axis=1)\n",
        "    idcg[idcg == 0.0] = 1.0\n",
        "    ndcg = dcg / idcg\n",
        "    ndcg[torch.isnan(ndcg)] = 0.0\n",
        "    return torch.mean(ndcg).item()\n",
        "\n",
        "\n",
        "def get_metrics(\n",
        "    model, edge_index, exclude_edge_indices, k, batch_size=1024, device=None\n",
        "):\n",
        "    if device is None:\n",
        "        device = next(model.parameters()).device\n",
        "\n",
        "    user_embedding = model.authors_emb.weight.to(device)\n",
        "    item_embedding = model.papers_emb.weight.to(device)\n",
        "\n",
        "    users = edge_index[0].unique()\n",
        "    test_user_pos_items = get_author_positive_papers(edge_index)\n",
        "\n",
        "    # Precompute “seen” items (train/val/test) per user to mask\n",
        "    exclude_dicts = [get_author_positive_papers(ei) for ei in exclude_edge_indices]\n",
        "\n",
        "    r_all = []\n",
        "    for start in range(0, users.numel(), batch_size):\n",
        "        batch_users = users[start : start + batch_size]\n",
        "        u_ids = batch_users.tolist()\n",
        "        u_emb = user_embedding[batch_users].to(device)  # [B, d]\n",
        "\n",
        "        rating = torch.matmul(u_emb, item_embedding.T)  # [B, num_items]\n",
        "\n",
        "        # mask excluded items for each user in this batch\n",
        "        for row, u in enumerate(u_ids):\n",
        "            seen_items = set()\n",
        "            for d in exclude_dicts:\n",
        "                seen_items.update(d.get(u, []))\n",
        "            if seen_items:\n",
        "                rating[row, list(seen_items)] = -(1 << 10)\n",
        "\n",
        "        _, top_K_items = torch.topk(rating, k=k, dim=1)  # [B, k]\n",
        "\n",
        "        # build r for this batch\n",
        "        for row, u in enumerate(u_ids):\n",
        "            ground_truth_items = test_user_pos_items[u]\n",
        "            label = [int(i in ground_truth_items) for i in top_K_items[row].tolist()]\n",
        "            r_all.append(label)\n",
        "\n",
        "    r = torch.tensor(r_all, dtype=torch.float32)\n",
        "    test_user_pos_items_list = [test_user_pos_items[u.item()] for u in users]\n",
        "\n",
        "    recall, precision = RecallPrecision_ATk(test_user_pos_items_list, r, k)\n",
        "    ndcg = NDCGatK_r(test_user_pos_items_list, r, k)\n",
        "    return recall, precision, ndcg\n",
        "\n",
        "\n",
        "# wrapper function to evaluate model\n",
        "def evaluation(\n",
        "    model,\n",
        "    edge_index,\n",
        "    sparse_edge_index,\n",
        "    exclude_edge_indices,\n",
        "    k,\n",
        "):\n",
        "    \"\"\"Evaluates model loss and metrics including recall, precision, ndcg @ k\n",
        "\n",
        "    Args:\n",
        "        model (LighGCN): lightgcn model\n",
        "        edge_index (torch.Tensor): 2 by N list of edges for split to evaluate\n",
        "        sparse_edge_index (sparseTensor): sparse adjacency matrix for split to evaluate\n",
        "        exclude_edge_indices ([type]): 2 by N list of edges for split to discount from evaluation\n",
        "        k (int): determines the top k items to compute metrics on\n",
        "\n",
        "    Returns:\n",
        "        tuple: bpr loss, recall @ k, precision @ k, ndcg @ k\n",
        "    \"\"\"\n",
        "    # get embeddings\n",
        "    (\n",
        "        users_emb_final,\n",
        "        items_emb_final,\n",
        "    ) = model.forward(sparse_edge_index)\n",
        "\n",
        "    user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(\n",
        "        edge_index,\n",
        "        batch_size=128,\n",
        "    )\n",
        "    users_emb_final = users_emb_final[user_indices]\n",
        "    pos_items_emb_final = items_emb_final[pos_item_indices]\n",
        "    neg_items_emb_final = items_emb_final[neg_item_indices]\n",
        "\n",
        "    loss = bpr_loss(\n",
        "        users_emb_final,\n",
        "        pos_items_emb_final,\n",
        "        neg_items_emb_final,\n",
        "    ).item()\n",
        "\n",
        "    recall, precision, ndcg = get_metrics(model, edge_index, exclude_edge_indices, k)\n",
        "\n",
        "    return loss, recall, precision, ndcg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYw1cUgPTjws"
      },
      "source": [
        "# Training\n",
        "\n",
        "Your test set performance should be in line with the following (*K=20*):\n",
        "\n",
        "*Recall@K: 0.13, Precision@K: 0.045, NDCG@K: 0.10*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MQL2W-NQTeFd"
      },
      "outputs": [],
      "source": [
        "# define contants\n",
        "ITERATIONS = 10000\n",
        "BATCH_SIZE = 1024\n",
        "LR = 1e-3\n",
        "ITERS_PER_EVAL = 200\n",
        "ITERS_PER_LR_DECAY = 200\n",
        "K = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49JDkBtKTfE-",
        "outputId": "0a62891e-4a65-4b8c-c5d1-1316281b50c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device cpu.\n"
          ]
        }
      ],
      "source": [
        "# setup\n",
        "model = LightGCN(\n",
        "    num_authors=num_authors,\n",
        "    num_papers=num_papers,\n",
        "    embedding_dim=64,\n",
        "    K=6,\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device {device}.\")\n",
        "\n",
        "\n",
        "model = model.to(device)\n",
        "model.train()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "edge_index = edge_index.to(device)\n",
        "train_edge_index = train_edge_index.to(device)\n",
        "train_sparse_edge_index = train_sparse_edge_index.to(device)\n",
        "\n",
        "val_edge_index = val_edge_index.to(device)\n",
        "val_sparse_edge_index = val_sparse_edge_index.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYjrDp1w-hiP",
        "outputId": "ce7f5102-2090-44a0-8245-42fa30853679"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Iteration 0/10000] train_loss: -0.6931, val_loss: -0.6932, val_recall@20: 0.0004, val_precision@20: 4e-05, val_ndcg@20: 0.00015\n"
          ]
        }
      ],
      "source": [
        "# training loop\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for iter in range(ITERATIONS):\n",
        "    # forward propagation\n",
        "    authors_emb_final, papers_emb_final = model.forward(train_sparse_edge_index)\n",
        "\n",
        "    # mini batching\n",
        "    (\n",
        "        batched_author_indices,\n",
        "        batched_pos_paper_indices,\n",
        "        batched_neg_paper_indices,\n",
        "    ) = sample_mini_batch(\n",
        "        train_edge_index,\n",
        "        BATCH_SIZE,\n",
        "    )\n",
        "\n",
        "    batched_author_indices = batched_author_indices.to(device)\n",
        "    batched_pos_paper_indices = batched_pos_paper_indices.to(device)\n",
        "    batched_neg_paper_indices = batched_neg_paper_indices.to(device)\n",
        "\n",
        "    authors_emb_final = authors_emb_final[batched_author_indices]\n",
        "    pos_items_emb_final = papers_emb_final[batched_pos_paper_indices]\n",
        "    neg_items_emb_final = papers_emb_final[batched_neg_paper_indices]\n",
        "\n",
        "    # loss computation\n",
        "    train_loss = bpr_loss(\n",
        "        authors_emb_final,\n",
        "        pos_items_emb_final,\n",
        "        neg_items_emb_final,\n",
        "    )\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if iter % ITERS_PER_EVAL == 0:\n",
        "        model.eval()\n",
        "        val_loss, recall, precision, ndcg = evaluation(\n",
        "            model,\n",
        "            val_edge_index,\n",
        "            val_sparse_edge_index,\n",
        "            [train_edge_index],\n",
        "            K,\n",
        "        )\n",
        "        print(\n",
        "            f\"[Iteration {iter}/{ITERATIONS}] train_loss: {round(train_loss.item(), 5)}, val_loss: {round(val_loss, 5)}, val_recall@{K}: {round(recall, 5)}, val_precision@{K}: {round(precision, 5)}, val_ndcg@{K}: {round(ndcg, 5)}\"\n",
        "        )\n",
        "        train_losses.append(train_loss.item())\n",
        "        val_losses.append(val_loss)\n",
        "        model.train()\n",
        "\n",
        "    if iter % ITERS_PER_LR_DECAY == 0 and iter != 0:\n",
        "        scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "nLcdvV5iXBSv",
        "outputId": "b4059176-24b0-46b5-ea65-68c2f9afd6d2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "iters = [iter * ITERS_PER_EVAL for iter in range(len(train_losses))]\n",
        "plt.plot(iters, train_losses, label='train')\n",
        "plt.plot(iters, val_losses, label='validation')\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')\n",
        "plt.title('training and validation loss curves')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6UjCTMQ_N5e",
        "outputId": "56d092d1-df05-4e7d-f2d9-5deead054d7c"
      },
      "outputs": [],
      "source": [
        "# evaluate on test set\n",
        "model.eval()\n",
        "test_edge_index = test_edge_index.to(device)\n",
        "test_sparse_edge_index = test_sparse_edge_index.to(device)\n",
        "\n",
        "test_loss, test_recall, test_precision, test_ndcg = evaluation(\n",
        "    model,\n",
        "    test_edge_index,\n",
        "    test_sparse_edge_index,\n",
        "    [train_edge_index, val_edge_index],\n",
        "    K,\n",
        "    LAMBDA,\n",
        ")\n",
        "\n",
        "print(\n",
        "    f\"[test_loss: {round(test_loss, 5)}, test_recall@{K}: {round(test_recall, 5)}, test_precision@{K}: {round(test_precision, 5)}, test_ndcg@{K}: {round(test_ndcg, 5)}\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "default",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
