{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T02:11:05.545309Z",
     "start_time": "2025-11-07T02:11:03.894116Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import HeteroData\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "\n",
    "FILE_DIR = \"\"\n",
    "data_path = os.path.join(FILE_DIR, \"data\", \"processed_normalized_data.pkl\")\n",
    "output_path = os.path.join(FILE_DIR, \"data\", \"hetero_data.pt\")\n",
    "\n",
    "data: pd.DataFrame = pd.read_pickle(data_path)"
   ],
   "id": "7d9c34b7d7d901e5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T02:06:46.029538Z",
     "start_time": "2025-11-07T02:06:46.018269Z"
    }
   },
   "cell_type": "code",
   "source": "data.columns",
   "id": "3951202a336bec54",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'abstract', 'url', 'authors', 'conference', 'year',\n",
       "       'embedding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T02:06:50.675887Z",
     "start_time": "2025-11-07T02:06:50.667318Z"
    }
   },
   "cell_type": "code",
   "source": "data.year",
   "id": "e7f1c2b7b0ca22e0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2020\n",
       "1        2020\n",
       "2        2020\n",
       "3        2020\n",
       "4        2020\n",
       "         ... \n",
       "63849    2012\n",
       "63850    2012\n",
       "63851    2012\n",
       "63852    2012\n",
       "63853    2012\n",
       "Name: year, Length: 63854, dtype: Int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-07T02:23:19.496697Z",
     "start_time": "2025-11-07T02:23:18.266728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Graph stats\n",
    "#!/usr/bin/env python3\n",
    "import argparse\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import torch\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "import torch_geometric.transforms as T\n",
    "\n",
    "\n",
    "def main(path: str, list_top: int):\n",
    "    # 1) Load hetero graph\n",
    "    hetero_data = torch.load(path, weights_only=False)\n",
    "    # Ensure undirected (safe even if already done)\n",
    "    hetero_data = T.ToUndirected()(hetero_data)\n",
    "\n",
    "    # 2) Collapse to a single homogeneous graph (keeps node/edge type ids)\n",
    "    homo = hetero_data.to_homogenous()\n",
    "\n",
    "    # 3) Convert to a NetworkX graph\n",
    "    #    Using an undirected simple Graph for connected components\n",
    "    G = to_networkx(homo, to_undirected=True)\n",
    "\n",
    "    # 4) Connected components and sizes\n",
    "    components = list(nx.connected_components(G))\n",
    "    sizes = [len(c) for c in components]\n",
    "    sizes_sorted = sorted(sizes, reverse=True)\n",
    "\n",
    "    print(f\"# Nodes (homogeneous): {G.number_of_nodes()}\")\n",
    "    print(f\"# Edges (homogeneous): {G.number_of_edges()}\")\n",
    "    print(f\"# Connected components: {len(components)}\\n\")\n",
    "\n",
    "    # 5) Print size list (largest first)\n",
    "    print(\"Component sizes (descending):\")\n",
    "    print(sizes_sorted)\n",
    "    if list_top > 0:\n",
    "        print(f\"\\nTop {min(list_top, len(components))} components shown with type breakdown:\")\n",
    "\n",
    "    # 6) Optional: per-component type breakdown\n",
    "    #    - homo.node_type is a tensor of ints mapping each node -> type index\n",
    "    #    - hetero_data.node_types lists type names in matching order\n",
    "    node_type_tensor = homo.node_type.cpu() if hasattr(homo, \"node_type\") else None\n",
    "    type_names = list(getattr(hetero_data, \"node_types\", []))\n",
    "\n",
    "    # Build a helper for quick lookups\n",
    "    # G nodes are 0..N-1 in the same order as homogeneous nodes\n",
    "    for rank, comp_nodes in enumerate(\n",
    "        sorted(components, key=lambda c: len(c), reverse=True)[:max(0, list_top)]\n",
    "    ):\n",
    "        comp_size = len(comp_nodes)\n",
    "        breakdown = {}\n",
    "        if node_type_tensor is not None and type_names:\n",
    "            # Count node types inside this component\n",
    "            counts = Counter(int(node_type_tensor[n].item()) for n in comp_nodes)\n",
    "            breakdown = {type_names[t]: counts[t] for t in counts}\n",
    "        print(f\"  - Component #{rank+1}: size={comp_size}, types={breakdown if breakdown else 'n/a'}\")\n",
    "\n",
    "    # 7) If you’d like the raw list for downstream use, you can easily return or save it here.\n",
    "    # (For now we just print it.)\n",
    "\n",
    "\n",
    "main(\"data/hetero_data.pt\", list_top=0)"
   ],
   "id": "c90410c9aa5332c8",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HeteroData' has no attribute 'to_homogenous'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 63\u001B[39m\n\u001B[32m     57\u001B[39m         \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m  - Component #\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mrank+\u001B[32m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m: size=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcomp_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, types=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbreakdown\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mif\u001B[39;00m\u001B[38;5;250m \u001B[39mbreakdown\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01melse\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[33m'\u001B[39m\u001B[33mn/a\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     59\u001B[39m     \u001B[38;5;66;03m# 7) If you’d like the raw list for downstream use, you can easily return or save it here.\u001B[39;00m\n\u001B[32m     60\u001B[39m     \u001B[38;5;66;03m# (For now we just print it.)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m63\u001B[39m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mdata/hetero_data.pt\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlist_top\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 19\u001B[39m, in \u001B[36mmain\u001B[39m\u001B[34m(path, list_top)\u001B[39m\n\u001B[32m     16\u001B[39m hetero_data = T.ToUndirected()(hetero_data)\n\u001B[32m     18\u001B[39m \u001B[38;5;66;03m# 2) Collapse to a single homogeneous graph (keeps node/edge type ids)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m homo = \u001B[43mhetero_data\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_homogenous\u001B[49m()\n\u001B[32m     21\u001B[39m \u001B[38;5;66;03m# 3) Convert to a NetworkX graph\u001B[39;00m\n\u001B[32m     22\u001B[39m \u001B[38;5;66;03m#    Using an undirected simple Graph for connected components\u001B[39;00m\n\u001B[32m     23\u001B[39m G = to_networkx(homo, to_undirected=\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/miniconda3/envs/PaperTrail/lib/python3.13/site-packages/torch_geometric/data/hetero_data.py:162\u001B[39m, in \u001B[36mHeteroData.__getattr__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m    160\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mbool\u001B[39m(re.search(\u001B[33m'\u001B[39m\u001B[33m_dict$\u001B[39m\u001B[33m'\u001B[39m, key)):\n\u001B[32m    161\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.collect(key[:-\u001B[32m5\u001B[39m])\n\u001B[32m--> \u001B[39m\u001B[32m162\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.\u001B[34m__class__\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m has no \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    163\u001B[39m                      \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mattribute \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mAttributeError\u001B[39m: 'HeteroData' has no attribute 'to_homogenous'"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "dc9d79aa97f128f3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
