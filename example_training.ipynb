{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "torch_version = str(torch.__version__)\n",
        "scatter_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "sparse_src = f\"https://pytorch-geometric.com/whl/torch-{torch_version}.html\"\n",
        "!pip install torch-scatter -f $scatter_src\n",
        "!pip install torch-sparse -f $sparse_src\n",
        "!pip install torch-geometric\n",
        "!pip install -q git+https://github.com/snap-stanford/deepsnap.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aYr3ZEZ6foGM",
        "outputId": "f3a0d86e-7871-4354-e2d7-e030dfc5ee3b"
      },
      "id": "aYr3ZEZ6foGM",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.12/dist-packages (2.1.2+pt28cu126)\n",
            "Looking in links: https://pytorch-geometric.com/whl/torch-2.8.0+cu126.html\n",
            "Requirement already satisfied: torch-sparse in /usr/local/lib/python3.12/dist-packages (0.6.18+pt28cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.12/dist-packages (2.7.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.10.5)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "4276ad41",
      "metadata": {
        "id": "4276ad41"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.loader import LinkNeighborLoader\n",
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "f8b263d2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8b263d2",
        "outputId": "cf4e4cd9-5ab0-48e8-de4d-bb332112e5b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  author={ node_id=[90941] },\n",
              "  paper={\n",
              "    node_id=[63854],\n",
              "    x=[63854, 256],\n",
              "  },\n",
              "  (author, writes, paper)={ edge_index=[2, 320187] },\n",
              "  (paper, rev_writes, author)={ edge_index=[2, 320187] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# Lets start by loading the data\n",
        "\n",
        "data = torch.load(\"hetero_data_no_coauthor.pt\", weights_only=False)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "52b1ac43",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52b1ac43",
        "outputId": "4bab84df-1044-4bf8-dc68-92d3b2377891"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  author={ node_id=[90941] },\n",
              "  paper={\n",
              "    node_id=[63854],\n",
              "    x=[63854, 256],\n",
              "  },\n",
              "  (author, writes, paper)={\n",
              "    edge_index=[2, 179306],\n",
              "    edge_label=[76845],\n",
              "    edge_label_index=[2, 76845],\n",
              "  },\n",
              "  (paper, rev_writes, author)={ edge_index=[2, 179306] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Do the Train, Val, Test Split\n",
        "# training (80%), validation (10%), and testing edges (10%).\n",
        "# Across the training edges, we use 70% of edges for message passing,\n",
        "# and 30% of edges for supervision. (This is from a tutorial by PyG, we can change this later)\n",
        "# We further want to generate fixed negative edges for evaluation with a ratio of 2:1. (Again a Hyperparameter we can tune later)\n",
        "# Negative edges during training will be generated on-the-fly (How?, again this is from the tutorial, need to check later)\n",
        "transform = T.RandomLinkSplit(\n",
        "    num_val=0.1, # Validation set percentage\n",
        "    num_test=0.1, # Test set percentage\n",
        "    disjoint_train_ratio=0.3, # Percentage of training edges used for supervision, these will not be used for message passing\n",
        "    neg_sampling_ratio=2.0, # Ratio of negative to positive edges for validation and testing, dont know how this is related to `add_negative_train_samples`, need to check later\n",
        "    add_negative_train_samples=False, # AYYY NO idea, why this set to False, but somehow it works worse with True ???, Need it investigate later, Prolly because we do LinkNeighborLoader which samples neg edges for us?\n",
        "    edge_types=(\"author\", \"writes\", \"paper\"), # Any ways, these are the edge types we want to predict\n",
        "    rev_edge_types=(\"paper\", \"rev_writes\", \"author\"), # Reverse edge types, so we dont accidentally bleed information into validation/test set\n",
        ")\n",
        "\n",
        "train_data, val_data, test_data = transform(data)\n",
        "train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "dc5452de",
      "metadata": {
        "id": "dc5452de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4643fa82-9990-4e70-9182-7cbb6705458d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch_geometric/loader/link_neighbor_loader.py:252: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
            "  neighbor_sampler = NeighborSampler(\n"
          ]
        }
      ],
      "source": [
        "# In the first hop, we sample at most 20 neighbors.\n",
        "# In the second hop, we sample at most 10 neighbors.\n",
        "# In addition, during training, we want to sample negative edges on-the-fly with\n",
        "# a ratio of 2:1.\n",
        "# We can make use of the `loader.LinkNeighborLoader` from PyG:\n",
        "\n",
        "# This loader is actually SAMPLING the full graph, by first sampling 64 random nodes then 32 neighbors of each node previously sampled node to create a sparse subgraph etc...\n",
        "# We should be able to load the graph fully into memory, but how would one train that?\n",
        "# We could probably use the previous random link split to do full batch training, but somehow we would not sample random negative edges then?\n",
        "# Need to check different loaders which sample the full graph and then do negative sampling on-the-fly\n",
        "edge_label_index = train_data[\"author\", \"writes\", \"paper\"].edge_label_index\n",
        "edge_label = train_data[\"author\", \"writes\", \"paper\"].edge_label\n",
        "\n",
        "train_loader = LinkNeighborLoader(\n",
        "    data=train_data,\n",
        "    num_neighbors=[64, 32, 16],\n",
        "    neg_sampling_ratio=2.0,\n",
        "    edge_label_index=((\"author\", \"writes\", \"paper\"), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "b026ef6e",
      "metadata": {
        "id": "b026ef6e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Simple 3 hop GNN\n",
        "class GNN(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv(\n",
        "            hidden_channels,\n",
        "            hidden_channels,\n",
        "            aggr=\"mean\",\n",
        "            project=False,\n",
        "        )\n",
        "        self.conv2 = SAGEConv(\n",
        "            hidden_channels,\n",
        "            hidden_channels,\n",
        "            aggr=\"mean\",\n",
        "            project=False,\n",
        "        )\n",
        "        self.conv3 = SAGEConv(\n",
        "            hidden_channels,\n",
        "            hidden_channels,\n",
        "            aggr=\"mean\",\n",
        "            project=False,\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, edge_index: torch.Tensor) -> torch.Tensor:\n",
        "        x = F.relu(self.conv1(x, edge_index))\n",
        "        x = F.relu(self.conv2(x, edge_index))\n",
        "        x = self.conv3(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Our final classifier applies the dot-product between source and destination\n",
        "# node embeddings to derive edge-level predictions:\n",
        "class Classifier(torch.nn.Module):\n",
        "    def forward(\n",
        "        self,\n",
        "        x_user: torch.Tensor,\n",
        "        x_movie: torch.Tensor,\n",
        "        edge_label_index: torch.Tensor,\n",
        "    ) -> torch.Tensor:\n",
        "        # Convert node embeddings to edge-level representations:\n",
        "        edge_feat_user = x_user[edge_label_index[0]]\n",
        "        edge_feat_movie = x_movie[edge_label_index[1]]\n",
        "        return (edge_feat_user * edge_feat_movie).sum(dim=-1)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels: int, data: HeteroData):\n",
        "        super().__init__()\n",
        "\n",
        "        self.hidden_channels = hidden_channels\n",
        "\n",
        "        # Instantiate homogeneous GNN:\n",
        "        self.gnn = GNN(hidden_channels)\n",
        "\n",
        "        # Convert GNN model into a heterogeneous variant:\n",
        "        self.gnn = to_hetero(self.gnn, metadata=data.metadata())\n",
        "\n",
        "        # Instantiate link classifier:\n",
        "        self.classifier = Classifier()\n",
        "\n",
        "    def forward(self, data: HeteroData) -> torch.Tensor:\n",
        "\n",
        "        # Set the initial user embeddings to all ones for all authors\n",
        "        # This makes sure the graph can generalize to unseen authors during inference\n",
        "        author_embedding = torch.ones(\n",
        "            (data[\"author\"].num_nodes, self.hidden_channels),\n",
        "            device=data[\"paper\"].x.device,\n",
        "        )\n",
        "\n",
        "        # Extract paper embeddings from the data object\n",
        "        paper_embedding = data[\"paper\"].x\n",
        "\n",
        "        # Noew we can create the x_dict required for the GNN\n",
        "        x_dict = {\n",
        "            \"author\": author_embedding,\n",
        "            \"paper\": paper_embedding,\n",
        "        }\n",
        "\n",
        "        # \"x_dict\" now holds feature matrices of all node types\n",
        "        # \"edge_index_dict\" holds all edge indices, i.e. the connections between users and movies\n",
        "        # The GNN will predict new embeddings for all node types, we can even check how the user embeddings change\n",
        "        gnn_pred = self.gnn(x_dict, data.edge_index_dict)\n",
        "\n",
        "        # Finally we can use the classifier to get the final link predictions\n",
        "        # This can be done either with the dot product of the updated embeddings\n",
        "        # or more involved with a linear projection head or smth similar\n",
        "        cls_pred = self.classifier(\n",
        "            gnn_pred[\"author\"],\n",
        "            gnn_pred[\"paper\"],\n",
        "            data[\"author\", \"writes\", \"paper\"].edge_label_index,\n",
        "        )\n",
        "\n",
        "        return cls_pred"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_scatter import scatter_mean\n",
        "class BaselineNoGraphModel(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels: int, data: HeteroData):\n",
        "        super().__init__()\n",
        "        self.hidden_channels = hidden_channels\n",
        "\n",
        "        # Use the correct per-type input sizes\n",
        "        paper_in = data[\"paper\"].num_features\n",
        "        # author_in = data[\"author\"].num_features  # not used in this baseline\n",
        "\n",
        "        # Project paper features to hidden size\n",
        "        self.lin_paper = torch.nn.Linear(paper_in, hidden_channels, bias=True)\n",
        "\n",
        "        # Optional extra transform on the aggregated author representation\n",
        "        self.lin_author = torch.nn.Linear(hidden_channels, hidden_channels, bias=True)\n",
        "\n",
        "        self.classifier = Classifier()  # assumes signature: (author_emb, paper_emb, edge_label_index) -> scores\n",
        "\n",
        "    def forward(self, data: HeteroData) -> torch.Tensor:\n",
        "        edge_type = (\"author\", \"writes\", \"paper\")\n",
        "        edge_index = data[edge_type].edge_index\n",
        "        author_ids, paper_ids = edge_index[0], edge_index[1]\n",
        "\n",
        "        # 1) Paper embeddings\n",
        "        paper_x = data[\"paper\"].x  # [num_papers, paper_in]\n",
        "        paper_h = self.lin_paper(paper_x)  # [num_papers, hidden]\n",
        "\n",
        "        # 2) Build author embeddings by averaging their authored papers' embeddings\n",
        "        num_authors = data[\"author\"].num_nodes\n",
        "        # paper_h[paper_ids] picks each written paper's embedding; scatter to author_ids\n",
        "        author_h = scatter_mean(\n",
        "            paper_h[paper_ids],\n",
        "            author_ids,\n",
        "            dim=0,\n",
        "            dim_size=num_authors,  # ensures we get a row for every author (zeros for authors with no papers)\n",
        "        )\n",
        "        author_h = self.lin_author(author_h)  # [num_authors, hidden]\n",
        "\n",
        "        # 3) Score candidate pairs (author, paper) at edge_label_index\n",
        "        cls_pred = self.classifier(\n",
        "            author_h,\n",
        "            paper_h,\n",
        "            data[edge_type].edge_label_index,\n",
        "        )\n",
        "        return cls_pred"
      ],
      "metadata": {
        "id": "eQQ8Kf56bnHW"
      },
      "id": "eQQ8Kf56bnHW",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "eea251cb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eea251cb",
        "outputId": "6a6028b6-c599-4854-a2a9-9fa5d6cb6813"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:44<00:00, 13.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 0.6041\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:35<00:00, 16.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 0.5136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:36<00:00, 16.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 002, Loss: 0.4832\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:35<00:00, 16.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 003, Loss: 0.4603\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:35<00:00, 16.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 004, Loss: 0.4493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:35<00:00, 16.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 005, Loss: 0.4396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:35<00:00, 16.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 006, Loss: 0.4275\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:35<00:00, 16.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 007, Loss: 0.4210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:35<00:00, 16.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 008, Loss: 0.4167\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:35<00:00, 16.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 009, Loss: 0.4119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:38<00:00, 15.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 010, Loss: 0.4100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:35<00:00, 16.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 011, Loss: 0.4071\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:36<00:00, 16.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 012, Loss: 0.4053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:35<00:00, 16.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 013, Loss: 0.4012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:35<00:00, 16.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 014, Loss: 0.3979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:35<00:00, 16.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 015, Loss: 0.3964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:35<00:00, 16.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 016, Loss: 0.3929\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:35<00:00, 16.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 017, Loss: 0.3939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:35<00:00, 16.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 018, Loss: 0.3894\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:35<00:00, 16.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 019, Loss: 0.3877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "LR = 0.001\n",
        "EPOCHS = 20\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = Model(hidden_channels=256, data=data)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        sampled_data.to(device)\n",
        "\n",
        "        y_pred = model(sampled_data)\n",
        "        y_true = sampled_data[\"author\", \"writes\", \"paper\"].edge_label\n",
        "\n",
        "        loss = F.binary_cross_entropy_with_logits(y_pred, y_true)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * y_pred.numel()\n",
        "        total_examples += y_pred.numel()\n",
        "\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "d1ab7387",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d1ab7387",
        "outputId": "aa2c545a-1d5c-498f-f133-f1b143c78ac0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on Test set...\n",
            "Precision: 0.8251\n",
            "Recall: 0.6633\n",
            "F1 Score: 0.7354\n",
            "Accuracy: 0.8409\n",
            "--------------------------------------------------\n",
            "Evaluating on validation set...\n",
            "Precision: 0.8316\n",
            "Recall: 0.6448\n",
            "F1 Score: 0.7264\n",
            "Accuracy: 0.8381\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(model, data):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_pred = model(data)\n",
        "\n",
        "    y_pred = y_pred.cpu().numpy()\n",
        "    y_true = data[\"author\", \"writes\", \"paper\"].edge_label.cpu().numpy()\n",
        "\n",
        "    # binary thresholding at 0.5\n",
        "    y_pred = (y_pred >= 0.5)\n",
        "\n",
        "    FP = ((y_true == 0) & (y_pred == 1)).sum().item()\n",
        "    TP = ((y_true == 1) & (y_pred == 1)).sum().item()\n",
        "    FN = ((y_true == 1) & (y_pred == 0)).sum().item()\n",
        "    TN = ((y_true == 0) & (y_pred == 0)).sum().item()\n",
        "\n",
        "    precision = TP / (TP + FP + 1e-8)\n",
        "    recall = TP / (TP + FN + 1e-8)\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
        "    accuracy = (TP + TN) / (TP + TN + FP + FN + 1e-8)\n",
        "\n",
        "    return precision, recall, f1_score, accuracy\n",
        "\n",
        "\n",
        "test_data.to(device)\n",
        "precision, recall, f1_score, accuracy = evaluate_model(model, test_data)\n",
        "print(\"Evaluating on Test set...\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1_score:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"--------------------------------------------------\")\n",
        "val_data.to(device)\n",
        "precision, recall, f1_score, accuracy = evaluate_model(model, val_data)\n",
        "print(\"Evaluating on validation set...\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1_score:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "58534c6c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58534c6c",
        "outputId": "fb5ade9b-09f1-4f61-f812-e6fa79fd9cbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation AUC: 0.9062\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "with torch.no_grad():\n",
        "    y_pred = model(val_data)\n",
        "\n",
        "y_pred = y_pred.cpu().numpy()\n",
        "y_true = val_data[\"author\", \"writes\", \"paper\"].edge_label.cpu().numpy()\n",
        "\n",
        "auc = roc_auc_score(y_true, y_pred)\n",
        "print(f\"Validation AUC: {auc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "@torch.no_grad()\n",
        "def evaluate_ranking_metrics(\n",
        "    model,\n",
        "    data,\n",
        "    edge_type=(\"author\", \"writes\", \"paper\"),\n",
        "    ks=(1, 3, 5, 10),\n",
        "    reduce=\"macro\",  # 'macro' = average over heads (recommended)\n",
        "    device=None,\n",
        "):\n",
        "    \"\"\"\n",
        "    Compute ranking-style metrics for link prediction / recommendation:\n",
        "      - Hits@K:   fraction of heads with >=1 positive in top-K\n",
        "      - Recall@K: average over heads of (positives in top-K / total positives)\n",
        "      - Precision@K: average over heads of (positives in top-K / K)\n",
        "      - MRR:      mean reciprocal rank of the first positive per head\n",
        "      - MAP:      mean average precision over heads\n",
        "      - NDCG@K:   average normalized DCG at K over heads\n",
        "\n",
        "    Assumptions:\n",
        "      - model(data) -> scores aligned with edge_label (1D)\n",
        "      - data[edge_type].edge_label in {0,1}\n",
        "      - data[edge_type].edge_label_index[0] are the \"head\" IDs to group by\n",
        "\n",
        "    Notes:\n",
        "      - Heads with zero positives are skipped for metrics that require a positive\n",
        "        (MRR, MAP, Recall@K, NDCG@K). For Precision@K and Hits@K we include all heads.\n",
        "      - Set `device` if you want to force inference on a specific device.\n",
        "    \"\"\"\n",
        "    if device is not None:\n",
        "        data = data.to(device)\n",
        "        model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    scores = model(data).detach()\n",
        "    labels = data[edge_type].edge_label\n",
        "    head_ids = data[edge_type].edge_label_index[0]\n",
        "\n",
        "    # move to cpu numpy\n",
        "    scores = scores.cpu().numpy().astype(np.float64)\n",
        "    labels = labels.cpu().numpy().astype(np.int64)\n",
        "    head_ids = head_ids.cpu().numpy().astype(np.int64)\n",
        "\n",
        "    # group indices by head\n",
        "    # heads_idx_map: head_id -> np.array(indices of edges for that head)\n",
        "    # This is robust if head_ids are not contiguous or sorted.\n",
        "    heads_idx_map = {}\n",
        "    for i, h in enumerate(head_ids):\n",
        "        heads_idx_map.setdefault(int(h), []).append(i)\n",
        "\n",
        "    # containers\n",
        "    hits_at_k = {k: [] for k in ks}\n",
        "    prec_at_k = {k: [] for k in ks}\n",
        "    rec_at_k  = {k: [] for k in ks}\n",
        "    ndcg_at_k = {k: [] for k in ks}\n",
        "    mrr_vals = []\n",
        "    ap_vals  = []\n",
        "\n",
        "    # helper: DCG with binary relevance\n",
        "    def dcg_at_k(y_true_sorted, k):\n",
        "        # y_true_sorted: binary labels sorted by descending score\n",
        "        rel = y_true_sorted[:k]\n",
        "        if rel.size == 0:\n",
        "            return 0.0\n",
        "        # log2 positions start at 2 for rank 1\n",
        "        discounts = 1.0 / np.log2(np.arange(2, rel.size + 2))\n",
        "        return np.sum(rel * discounts)\n",
        "\n",
        "    for h, idxs in heads_idx_map.items():\n",
        "        idxs = np.array(idxs, dtype=np.int64)\n",
        "        y = labels[idxs]\n",
        "        s = scores[idxs]\n",
        "\n",
        "        # sort by score desc\n",
        "        order = np.argsort(-s)\n",
        "        y_sorted = y[order]\n",
        "\n",
        "        num_pos = int(y.sum())\n",
        "\n",
        "        # Precision/Recall/Hits/NDCG@K\n",
        "        for k in ks:\n",
        "            topk = y_sorted[:k]\n",
        "            hits_at_k[k].append(1.0 if topk.sum() > 0 else 0.0)\n",
        "            prec_at_k[k].append(float(topk.sum()) / max(k, 1))\n",
        "\n",
        "            if num_pos > 0:\n",
        "                rec_at_k[k].append(float(topk.sum()) / num_pos)\n",
        "                # NDCG\n",
        "                dcg = dcg_at_k(y_sorted, k)\n",
        "                ideal_sorted = np.sort(y)[::-1]  # best-case ranking\n",
        "                idcg = dcg_at_k(ideal_sorted, k)\n",
        "                ndcg_at_k[k].append(dcg / idcg if idcg > 0 else 0.0)\n",
        "\n",
        "        # MRR + MAP only defined if there is at least one positive\n",
        "        if num_pos > 0:\n",
        "            # MRR\n",
        "            pos_ranks = np.where(y_sorted == 1)[0]  # 0-based ranks\n",
        "            first_rank = pos_ranks[0] + 1  # 1-based\n",
        "            mrr_vals.append(1.0 / first_rank)\n",
        "\n",
        "            # AP\n",
        "            # Precision at each position of a relevant item, averaged over #relevant\n",
        "            cum_pos = 0\n",
        "            prec_sum = 0.0\n",
        "            for rank, rel in enumerate(y_sorted, start=1):\n",
        "                if rel == 1:\n",
        "                    cum_pos += 1\n",
        "                    prec_sum += cum_pos / rank\n",
        "            ap_vals.append(prec_sum / num_pos)\n",
        "\n",
        "    # aggregate\n",
        "    def avg(lst):\n",
        "        return float(np.mean(lst)) if len(lst) > 0 else 0.0\n",
        "\n",
        "    results = {\n",
        "        \"num_heads\": len(heads_idx_map),\n",
        "        \"MRR\": avg(mrr_vals),\n",
        "        \"MAP\": avg(ap_vals),\n",
        "    }\n",
        "\n",
        "    for k in ks:\n",
        "        results[f\"Hits@{k}\"] = avg(hits_at_k[k])\n",
        "        results[f\"Precision@{k}\"] = avg(prec_at_k[k])\n",
        "        # Recall@K & NDCG@K are averaged over heads with positives only\n",
        "        results[f\"Recall@{k}\"] = avg(rec_at_k[k])\n",
        "        results[f\"NDCG@{k}\"] = avg(ndcg_at_k[k])\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "FwpNudbsiyGS"
      },
      "id": "FwpNudbsiyGS",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example usage:\n",
        "test_data = test_data.to(device)\n",
        "metrics = evaluate_ranking_metrics(model, test_data,\n",
        "    edge_type=(\"author\",\"writes\",\"paper\"), ks=(1,3,10), device=device)\n",
        "print(\"Ranking metrics on Test:\")\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpJUrLR5jMUx",
        "outputId": "0cc6d841-7958-4d00-f743-7574ac5b8165"
      },
      "id": "HpJUrLR5jMUx",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranking metrics on Test:\n",
            "num_heads: 56505.0000\n",
            "MRR: 0.9565\n",
            "MAP: 0.9542\n",
            "Hits@1: 0.3447\n",
            "Precision@1: 0.3447\n",
            "Recall@1: 0.7717\n",
            "NDCG@1: 0.9170\n",
            "Hits@3: 0.3753\n",
            "Precision@3: 0.1678\n",
            "Recall@3: 0.9725\n",
            "NDCG@3: 0.9642\n",
            "Hits@10: 0.3759\n",
            "Precision@10: 0.0561\n",
            "Recall@10: 0.9990\n",
            "NDCG@10: 0.9669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 0.001\n",
        "EPOCHS = 20\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = BaselineNoGraphModel(hidden_channels=256, data=data)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "model.train()\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        sampled_data.to(device)\n",
        "\n",
        "        y_pred = model(sampled_data)\n",
        "        y_true = sampled_data[\"author\", \"writes\", \"paper\"].edge_label\n",
        "\n",
        "        loss = F.binary_cross_entropy_with_logits(y_pred, y_true)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * y_pred.numel()\n",
        "        total_examples += y_pred.numel()\n",
        "\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ],
      "metadata": {
        "id": "9t-rpy39jyTV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15763d9f-2b80-4f53-9f32-538e28e9c716"
      },
      "id": "9t-rpy39jyTV",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:26<00:00, 22.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 0.5402\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:25<00:00, 23.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 0.4958\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:25<00:00, 23.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 002, Loss: 0.4853\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:25<00:00, 23.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 003, Loss: 0.4835\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:26<00:00, 22.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 004, Loss: 0.4795\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:25<00:00, 23.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 005, Loss: 0.4775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:25<00:00, 23.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 006, Loss: 0.4764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:24<00:00, 24.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 007, Loss: 0.4744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:25<00:00, 23.91it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 008, Loss: 0.4729\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:25<00:00, 23.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 009, Loss: 0.4711\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:25<00:00, 23.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 010, Loss: 0.4707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:25<00:00, 23.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 011, Loss: 0.4698\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:25<00:00, 23.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 012, Loss: 0.4674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:25<00:00, 23.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 013, Loss: 0.4674\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:25<00:00, 23.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 014, Loss: 0.4659\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:25<00:00, 23.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 015, Loss: 0.4649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:25<00:00, 23.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 016, Loss: 0.4655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:25<00:00, 23.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 017, Loss: 0.4632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:25<00:00, 23.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 018, Loss: 0.4629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 601/601 [00:25<00:00, 23.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 019, Loss: 0.4622\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Example usage:\n",
        "test_data = test_data.to(device)\n",
        "metrics = evaluate_ranking_metrics(model, test_data,\n",
        "    edge_type=(\"author\",\"writes\",\"paper\"), ks=(1,3,10), device=device)\n",
        "print(\"Ranking metrics on Test:\")\n",
        "for k, v in metrics.items():\n",
        "    print(f\"{k}: {v:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJ91qJvei0KE",
        "outputId": "98ba9b90-5aee-439a-f2f6-0a015879633c"
      },
      "id": "rJ91qJvei0KE",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranking metrics on Test:\n",
            "num_heads: 56505.0000\n",
            "MRR: 0.9511\n",
            "MAP: 0.9482\n",
            "Hits@1: 0.3409\n",
            "Precision@1: 0.3409\n",
            "Recall@1: 0.7620\n",
            "NDCG@1: 0.9071\n",
            "Hits@3: 0.3752\n",
            "Precision@3: 0.1675\n",
            "Recall@3: 0.9713\n",
            "NDCG@3: 0.9593\n",
            "Hits@10: 0.3759\n",
            "Precision@10: 0.0561\n",
            "Recall@10: 0.9990\n",
            "NDCG@10: 0.9626\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_data.to(device)\n",
        "precision, recall, f1_score, accuracy = evaluate_model(model, test_data)\n",
        "print(\"Evaluating on Test set...\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1_score:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(\"--------------------------------------------------\")\n",
        "val_data.to(device)\n",
        "precision, recall, f1_score, accuracy = evaluate_model(model, val_data)\n",
        "print(\"Evaluating on validation set...\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1 Score: {f1_score:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lh6lZ5J5j1t_",
        "outputId": "4ac6a1bc-c371-40c4-8416-6522ca51bf7c"
      },
      "id": "Lh6lZ5J5j1t_",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating on Test set...\n",
            "Precision: 0.7739\n",
            "Recall: 0.3906\n",
            "F1 Score: 0.5191\n",
            "Accuracy: 0.7588\n",
            "--------------------------------------------------\n",
            "Evaluating on validation set...\n",
            "Precision: 0.7860\n",
            "Recall: 0.3873\n",
            "F1 Score: 0.5190\n",
            "Accuracy: 0.7606\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sLb4eMoLpCx1"
      },
      "id": "sLb4eMoLpCx1",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}